# Model Registry Configuration

[[models]]
id = "heuristic"
name = "Heuristic Processor"
tier = "NoLLM"
provider = "Local"
cost_per_1k_tokens = 0.0
average_latency_ms = 1
context_window = 0
capabilities = ["PatternMatching", "Templates"]
available = true
requires_auth = false

[[models]]
id = "qwen-0.5b"
name = "Qwen 2.5 Coder 0.5B"
tier = "Tiny"
provider = "Local"
cost_per_1k_tokens = 0.0
average_latency_ms = 50
context_window = 2048
capabilities = ["Classification", "SimpleQuestions", "RequirementChecking"]
available = true
local_path = "models/qwen2.5-coder-0.5b-instruct-q4_k_m.gguf"
requires_auth = false

[[models]]
id = "phi-2"
name = "Microsoft Phi-2"
tier = "Tiny"
provider = "Ollama"
cost_per_1k_tokens = 0.0
average_latency_ms = 100
context_window = 2048
capabilities = ["Classification", "SimpleQuestions"]
available = false
api_endpoint = "http://localhost:11434"
requires_auth = false

[[models]]
id = "codellama-7b"
name = "Code Llama 7B"
tier = "Small"
provider = "Ollama"
cost_per_1k_tokens = 0.0
average_latency_ms = 500
context_window = 4096
capabilities = ["CodeGeneration", "CodeReview", "Testing"]
available = false
api_endpoint = "http://localhost:11434"
requires_auth = false

[[models]]
id = "mistral-7b"
name = "Mistral 7B"
tier = "Small"
provider = "Together"
cost_per_1k_tokens = 0.0002
average_latency_ms = 800
context_window = 8192
capabilities = ["CodeGeneration", "Questions"]
available = false
api_endpoint = "https://api.together.xyz"
requires_auth = true

[[models]]
id = "mixtral-8x7b"
name = "Mixtral 8x7B"
tier = "Medium"
provider = "Together"
cost_per_1k_tokens = 0.0006
average_latency_ms = 1500
context_window = 32768
capabilities = ["CodeGeneration", "CodeReview", "Architecture", "Explanation"]
available = false
api_endpoint = "https://api.together.xyz"
requires_auth = true

[[models]]
id = "codellama-34b"
name = "Code Llama 34B"
tier = "Medium"
provider = "Together"
cost_per_1k_tokens = 0.0008
average_latency_ms = 2000
context_window = 16384
capabilities = ["CodeGeneration", "ComplexCode", "Testing"]
available = false
api_endpoint = "https://api.together.xyz"
requires_auth = true

[[models]]
id = "claude-3-opus"
name = "Claude 3 Opus"
tier = "Large"
provider = "Anthropic"
cost_per_1k_tokens = 0.015
average_latency_ms = 3000
context_window = 200000
capabilities = ["Architecture", "ComplexCode", "SystemDesign", "Creativity"]
available = false
api_endpoint = "https://api.anthropic.com"
requires_auth = true

[[models]]
id = "gpt-4-turbo"
name = "GPT-4 Turbo"
tier = "Large"
provider = "OpenAI"
cost_per_1k_tokens = 0.01
average_latency_ms = 2500
context_window = 128000
capabilities = ["Architecture", "ComplexCode", "SystemDesign"]
available = false
api_endpoint = "https://api.openai.com"
requires_auth = true

# Provider Configurations

[[providers]]
name = "Local"
provider_type = "Local"
default_timeout_ms = 5000
max_retries = 3

[[providers]]
name = "Ollama"
provider_type = "Ollama"
base_url = "http://localhost:11434"
default_timeout_ms = 30000
max_retries = 3

[[providers]]
name = "OpenAI"
provider_type = "OpenAI"
api_key_env = "OPENAI_API_KEY"
base_url = "https://api.openai.com/v1"
default_timeout_ms = 60000
max_retries = 3
rate_limit_rpm = 3000

[[providers]]
name = "Anthropic"
provider_type = "Anthropic"
api_key_env = "ANTHROPIC_API_KEY"
base_url = "https://api.anthropic.com"
default_timeout_ms = 60000
max_retries = 3
rate_limit_rpm = 1000

[[providers]]
name = "Together"
provider_type = "Together"
api_key_env = "TOGETHER_API_KEY"
base_url = "https://api.together.xyz"
default_timeout_ms = 60000
max_retries = 3
rate_limit_rpm = 600